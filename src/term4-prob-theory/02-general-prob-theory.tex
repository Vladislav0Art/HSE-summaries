\Subsection{Колмогоровская модель теории вероятности}

\begin{definition}
    $(\Omega, \mathcal{F}, P)$ - вероятностное пространство.

    $\Omega$ - множество или пространство элементарных исходов.

    $\mathcal{F}$ - $\sigma$-алгебра подмножеств $\Omega$. Элементы $\mathcal{F}$ - случайный события.

    $P$ - мера на $\mathcal{F}$ с условием $P(\Omega) = 1$.

    \begin{remark}
        Если $\Omega$ не более чем счётно, то можно взять $\mathcal{F} = 2^{\Omega}$
    \end{remark}
\end{definition}

\begin{definition}
    Условная вероятность. $A$ - событие, такое, что $P(A) > 0$.
    Тогда $P(B | A) = \frac{P(B \cap A)}{P(A)}$, где $A, B \in \mathcal{F}$.
\end{definition}

\begin{definition}
    Независимые события $A$ и $B$. Если $P(A \cap B) = P(A) \cdot P(B)$
\end{definition}

\begin{definition}
    Независимость в совокупности $A_1, A_2 \ldots A_n$. $P(A_{i_1} \cap \ldots \cap A_{i_k}) = P(A_{i_1}) \cdot \ldots \cdot P({A_{i_k}})$
    для всевозможных наборов индексов.
\end{definition}

\begin{definition}
    Последовательность событий $A_1, A_2 \ldots $ независимы - любой конечный набор событий
    независим в совокупности.
\end{definition}

\begin{lemma}
    \textbf{Бореля-Кантелли}

    $A_1, A_2, \ldots$ случайные события.

    \begin{enumerate}
        \item {
            Если $\sum_{n = 1}^{\infty} P(A_n) < +\infty$, то вероятность, что случилось бесконечное число из них равна 0.
        }
        \item {
            Если $A_1, A_2, \ldots$ независимы и $\sum_{n = 1}^{\infty} P(A_n) = +\infty$, тогда
            
            $P(\text{случилось бесконечное число из $A_n$}) = 1$.
        }
    \end{enumerate}
\end{lemma}

\begin{proof}
    $B = \bigcap_{n = 1}^{\infty} \bigcup_{k = n}^{\infty} A_k$.

    $\omega \in B \Longleftrightarrow \omega \in \bigcup_{k = n}^{\infty} A_k \ \forall n \Longleftrightarrow w \in A_k$ для бесконечного количества индексов $k$.

    Док-во этого факта:

    \begin{enumerate}
        \item $\Leftarrow:$ Лежит в каждом объединении, значит лежит в $B$.
        \item $\Rightarrow:$ $\omega$ лежит в пересечении. Пусть лежит в конечном - возьмём самый большой номер и получим противоречие.
    \end{enumerate}

    Док-во теоремы:

    \begin{enumerate}
        \item $P(B) = 0$ - хотим доказать.
        
        $B \subset \bigcup_{k = n}^{\infty} A_k \Rightarrow P(B) \leqslant P(\bigcup_{k = n}^{\infty} A_k) \leqslant \sum_{k = n}^{\infty} P(A_k)$, 
        а это хвост сходящегося ряда, а он стремится к нулю.

        \item Давайте смотреть на $\bar{A_1}, \bar{A_2}, \ldots$ - независимые события (следует из упражнения с прошлой лекции).
        
        $P(\bigcap_{k = 1}^n \bar{A_k}) = \prod_{k = 1}^{n} P(\bar{A_k}) \to_{n \to \infty} \prod_{k = 1}^{\infty}  P(\bar{A_k})$

        Но всё вложено по убыванию, по монотонности меры получаем $P(\bigcap_{k = 1}^{\infty} \bar{A_k}) = \prod_{k = 1}^{\infty} P(\bar{A_k}) = 
        \prod_{k=1}^{\infty} (1 - P(A_k))$

        Прологарифмируем это равенство.

        % $\ln (P(\bigcap_{n}^{\infty} \bar{A_k})) = \sum{k = n}^{\infty} \ln (1 - P(A_k)) \leqslant - \sum{k = n}^{\infty} P(A_k) = -\infty$ - сумма
        % хвоста расходящегося ряда.

        $\ln (P(\bigcap_{k = n}^{\infty} \bar{A}_k)) = \sum_{k = n}^{\infty} \ln(1 - P(A_k)) \leqslant \sum_{k = n}^{\infty} (-P(A_k)) = -\infty$ -- сумма хвоста расходящегося ряда.

        А значит мы логарифмировали $0 \Rightarrow P(\bigcap_{k = n}^{\infty} \bar{A_k}) = 0 \Rightarrow P(\bigcup_{n=1}^{\infty} \bigcap_{k = n}^{\infty} \bar{A}_k) = 0 \Rightarrow P(\bar{B}) = 0 \Rightarrow$
        
        $\Rightarrow \overline{\bigcup_{n=1}^{\infty} \bigcap_{k = n}^{\infty} \bar{A}_k} = \bigcap_{n=1}^{\infty} \bigcup_{k=n}^{\infty} A_k = B \Rightarrow P(B) = 1$.

        Добавим, что $B = \bigcap_{n = 1}^{\infty} B_n$, где $B_1 \supset B_2 \supset \ldots$ и $P(B) = \lim P(B_n) = 1$.
    \end{enumerate}
\end{proof}

\begin{theorem}
    \textbf{Закон нуля и единицы}

    Если $A_1, A_2 \ldots$ независимы, то $P(B) = 0$ или $P(B) = 1$.
\end{theorem}

\begin{example}
    Испытания Бернулли, успех с вероятностью $p$,
    
    $P(\text{ОРО встречается бесконечное число раз}) = \ ?$.

    $A_n = $ случилось $\text{ОРО}$ на позициях $n, n + 1, n + 2$.

    Тогда $A_1, A_4, A_7, \ldots$ независимы. $P(A_j) = pqp = p^2 q > 0$.

    Лемма Бореля-Кантелли говорит: бесконечное кол-во $A_{3k + 1}$ случится, если $\sum_{k=1}^{\infty} {P(A_{3k + 1})} = +\infty \implies P(\text{ОРО встречается бесконечное число раз}) = 1$. 
\end{example}

\Subsection{Случайные величины}

\begin{definition}
    $(\Omega, \mathcal{F}, P)$ - вероятностное пространство.

    $\xi: \Omega \to \mathbb{R}$ - случайная величина, если 
    это измеримая функция.
\end{definition}

\begin{definition}
    Распределение случайное величины

    $P_{\xi}$ - вероятностная мера на борелевских подмножествах 
    $\mathbb{R}$

    $A$ -- борелевское мн-во, $P_{\xi}(A) = P(\omega \in \Omega \ : \ \xi(\omega) \in A)$
\end{definition}

\begin{definition}
    Случаный величины $\xi$ и $\eta$ одинаково распределены, если
    $P_{\xi} = P_{\eta}$
\end{definition}

\begin{remark}
    $P_{\xi}$ однозначно определяются своими значениями на ячейках.

    $P_{\xi} (a, b] = P_{\xi} (-\infty, b] - P_{\xi} (-\infty, a] = 
    P(\xi \leqslant b) - P(\xi \leqslant a)$
\end{remark}

\begin{definition}
    Функция распределения случайной величины

    $F_{\xi} (x) = P(\xi \leqslant x)$
\end{definition}

\begin{properties}
    \begin{enumerate}
        \item {
        Функция распределения однозначно определяет распределение
        случайной величины.

        \textit{Доказательство:} Если у двух случайных величин совпали, то у них одинаковые
        распределения
        }
        \item {
            $0 \leqslant F_{\xi}(x) \leqslant 1 \, \forall x \in \mathbb{R}$
        }

        \item {
            $\lim_{x \to -\infty} F_{\xi} (x) = 0$

            $\lim_{x \to +\infty} F_{\xi} (x) = 1$

            \textit{Доказательство:} берём $x_n \to -\infty. A_n = \{ \xi \leqslant x_n \} $
            Тогда $A_{n + 1} \subset A_n$. Тогда $\lim_{n \to \infty} P(A_n) = 
            P(\bigcap_{n = 1}^{\infty} A_n) = P(\emptyset) = 0$
        } 
        \item {
            $F_{\xi}$ монотонно возрастает
        }
        \item {
            Непрерывность справа: $\lim_{y \to x+} F_{\xi} (y) = F_{\xi} (x)$

            \textit{Доказательство:} берём $y_n$ убывающие и $y_n \to x$.
            Тогда $A_n = \{ \xi \leqslant y_n \}$. $A_{n + 1} \subset A_n$.
            А тогда $\lim P(A_n) = P(\bigcup_{n = 1}^{\infty} A_n) = P(\xi \leqslant x) = F_{\xi} (x)$.
            Но с другой стороны $\lim P(A_n) = \lim P(\xi \leqslant y_n) = \lim F_{\xi} (y_n)$
        }
        \item {
            $\lim_{y \to x-} F_{\xi} (y) P(\xi < x)$

            \textit{Доказательство:} берём $y_n$ возрастающие и
            $y_n \to x$. $B_n = \{ \xi \leqslant y_n \}$ и $B_{n} \subset B_{n + 1}$.
            $\lim P(B_n) = P(\bigcup B_n) = P(\xi < x)$. Но с другой стороны
            $\lim P(B_n) = \lim F_{\xi} (y_n)$
        }
        \item {
            $F_{\xi + a} (x) = F_{\xi} (x - a)$

            \textit{Доказательство:} $\{ \xi + a \leqslant x \} = 
            \{ \xi \leqslant x - a \}$
        }
        \item {
            $F_{c\xi} = F_{\xi} (\frac{x}{c})$

            \textit{Доказательство:} $\{ c\xi \leqslant x \} = 
            \{ \xi \leqslant \frac{x}{c} \}$
        }
    \end{enumerate}

    \begin{remark}
        Фукнция, обладающая свойствами 3, 4, 5 - это фукнция распределения
        некоторой случайной величины.

        \textit{Доказательство:} пусть $g$ - такая функция. Тогда $\nu_g (a, b] = g(b) - g(a) $.
        Случайная величина $\xi (x) = x$. Тогда $F_{\xi} = g$
    \end{remark}

\end{properties}

\begin{definition}
    Случайная величина имеет дискретное распределение, если её 
    множество значений не более чем счётное.

    \begin{remark}
        \begin{enumerate}
            \item { $\xi \to \{y_1, y_2, \ldots \}$

            Если $x \neq y_k$, то $P(\xi = x) = 0$, т.е. $P_{\xi}(\{ x \}) = 0$
            }

            \item { $P_{\xi} (A) = \sum_{k : y_k \in A} P(\xi = y_k)$. Тут счётное
            число слагаемых, поэтому сумма корректно определена.
    
            Распределение однозначно определяется набором вероятностей $P(\xi = y_k)$
            }
            \item {
                $F_{\xi} (x) = \sum_{k : y_k \leqslant x} P(\xi = y_k)$
            }
        \end{enumerate}
    \end{remark}
\end{definition}

\begin{definition}
    Случайная величина имеет непрерывное распределение, если 
    $P(\xi = x) = 0$

    \begin{remark}
        \begin{enumerate}
            \item {
                Это значит, что фукнция распределения непрерывна.
            }
            \item {
                Непрерывные распределения бывают не очень хорошими, например
                Канторова лестница.
            }
        \end{enumerate}
    \end{remark}
\end{definition}

\begin{definition}
    Случайная величина имеет абсолютно непрерывное распределение, если 
    существует $p_{\xi} (t) \geqslant 0$, измеримая, т.ч. $F_{\xi} (x) = 
    \int_{-\infty}^x p_{\xi} (t) \, dt$ ($p_{\xi}(t)$ -- плотность распределения).
\end{definition}

\begin{properties}
    \begin{enumerate}
        \item {
            $A \subset \mathbb{R}$ -- борелевское, то $P_{\xi} (A) = \int_{A} p_{\xi} (t) \, dt$

            \textit{Доказательство:} слева мера и справа мера. Нужно понять, почему
            они совпадают на ячейках. 

            $P_{\xi} (a, b] = F_{\xi} (b) - F_{\xi} (a) = \int_{a}^b p_{\xi} (t) \, dt$
        }
        \item {
            $\int_{-\infty}^{+\infty} p_{\xi} (t) \, dt = 1$
        }
        \item {
            $p_{\xi}$ определена однозначно с точностью до почти везде (из теории меры)
        }
        \item {
            $F_{\xi}$ почти везде диффиренцируема и $F_{\xi}' (x) = p_{\xi} (x)$

            \textit{Доказательство:} а его не будет
        }
    \end{enumerate}
\end{properties}

\begin{example}
    \textbf{Вероятностные распределения}

    \begin{enumerate}
        \item {
            Биномиальное распределение: $\xi \sim Binom(p, n), 0 < p < 1$

            $\xi : \Omega \to \{ 0, 1, \ldots n \}$. $P(\xi = k) \binom{n}{k} p^k (1 - p)^{n - k}$ 
        }
        \item {
            Распределение Пуассона: $\xi \sim Poisson(\lambda), \lambda > 0$.

            $\xi : \Omega \to \{ 0, 1, \ldots \}$. $P(\xi = k) = \frac{\lambda^k}{k!}e^{-\lambda}$
        }
        \item {
            Геометрическое распределение: $\xi \sim Geom(p), 0 < p < 1$.

            $\xi : \Omega \to \{ 1, 2, \ldots \}$. $P(\xi = k) = p(1 - p)^{k - 1}$.
        }
        \item {
            Дискретные равномерные распределения: $\xi \sim U(\ldots)$

            $\xi : \Omega \to \{ 1, 2, \ldots n \}$. $P(\xi = k) = \frac{1}{n}$
        }
        \item {
            Непрерывно равномерное распределение: $\xi \sim U([a, b])$

            $\xi : \Omega \to [a, b]$. $p_{\xi}(t) = \frac{1}{b - a} \cdot \mathds{1}_{[a, b]} (t)$
        }
        \item {
            Нормальное распределение: $\xi \sim \mathcal{N} (a, \sigma^2), a \in \mathbb{R}, \sigma > 0$

            $\xi : \Omega \to \mathbb{R}$. $p_{\xi}(t) = \frac{1}{\sqrt{2\pi} \cdot \sigma} e^{-\frac{(t - a)^2}{2\sigma^2}}$

            Стандартное нормальное распределение: $\mathcal{N} (0, 1)$
        }
        \item {
            Экспонециальное распределение: $\xi \sim Exp(\lambda), \lambda > 0$.

            $\xi : \Omega \to [0, +\infty]$. $p_{\xi}(t) = \begin{cases}
                \lambda e^{-\lambda t}, \text{ при } t \geqslant 0 \\
                0, \text{ в других точках}
            \end{cases}$
        }
    \end{enumerate}

    \begin{remark}
        \begin{enumerate}
            \item {
                $\Phi (x) = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{x} e^{-\frac{t^2}{2}} \, dt$.

                На самом деле это функция распределения стандартной нормальной случайной величины.
            }
            \item {
                Если $\nu \sim \mathcal{N}(0, 1)$, то $\xi = \sigma \nu + a$. $\xi \sim \mathcal{N}(a, \sigma^2)$

                $F_{\xi} (x) = P(\sigma \nu + a \leqslant x) = P(\nu \leqslant \frac{x - a}{\sigma}) = \frac{1}{\sqrt{2 \pi}} 
                \int_{-\infty}^{\frac{x - a}{\sigma}} e^{-\frac{t^2}{2}} \, dt$

                Замена $t = \frac{s - a}{\sigma}$. Тогда $dt = \frac{ds}{\sigma}$

                Тогда: $\frac{1}{\sqrt{2 \pi}} 
                \int_{-\infty}^{\frac{x - a}{\sigma}} e^{-\frac{t^2}{2}} \, dt = \frac{1}{\sqrt{2\pi} \sigma}
                \int_{-\infty}^{x} e^{-\frac{(s - a)^2}{2\sigma^2}} \, ds$
            }
        \end{enumerate}
    
    \end{remark}
\end{example}

\Subsection{Совместное распределение}

\begin{definition}
    Совместное(многомерное) распределение.

    $\bar{\xi} = (\xi_1, \xi_2, \ldots, \xi_n) : \Omega \to \mathbb{R}^n$

    $P_{\bar{\xi}} (A) = P(\bar{\xi} \in A)$, где $A$ - борелевское подмножество $\mathbb{R}^n$ 

    \begin{remark}
        Совместное распределение однозначно определяет распределение случайной
        величины, но не наоборот

        \begin{example}
            $\xi, \eta : \Omega \to \{ 0, 1 \}$  с равными вероятностями.

            Если это были независимые подбрасывания: $(\xi, \eta) : \Omega \to
            \{ (0, 0), (0, 1), (1, 0), (1, 1) \}$  с равными вероятностями.

            Если $\xi = \eta$, то $(\xi, \eta) : \Omega \to \{ (0, 0), (1, 1) \}$.

        \end{example}
    \end{remark}
\end{definition}

\begin{definition}
    Случайные величины $\xi_1, \xi_2 \ldots \xi_n$ независимы, если для любых
    борелевских подмножеств $A_1, A_2 \ldots A_n \subset \mathbb{R}$, события
    $\{ \xi_1 \in A_1 \}, \ldots, \{ \xi_n \in A_n \}$ независимы

    \begin{remark}
        $P(\xi_1 \in A_1, \ldots, \xi_n \in A_n) = P(\xi_1 \in A_1) \cdot \ldots \cdot P(\xi_n \in A_n)$
    \end{remark}
\end{definition}

\begin{theorem}
    $\xi_1, \xi_2 \ldots \xi_n$ независимы $\Longleftrightarrow P_{\bar{\xi}} = P_{\xi_1} \times \ldots \times P_{\xi_n}$
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item $\Leftarrow$ очевидно. $P_{\bar{\xi}} (A_1 \times \ldots \times A_n) = P_{\xi_1} (A_1) \ldots P_{\xi_n}(A_n)$
        \item $\Rightarrow$. На множествах $A_1 \times \ldots \times A_n$ есть равенство + единственность продолжения.
    \end{enumerate}
\end{proof}

\begin{definition}
    Совместная (многомерная) функция распределения.

    $\bar{\xi} = (\xi_1 \ldots \xi_n)$. $F_{\bar{\xi}} : \mathbb{R}^n \to \mathbb{R}$. и
    $F_{\bar{\xi}} (\bar{x}) = P(\xi_1 \leqslant x_1,  \ldots, \xi_n \leqslant x_n) $
\end{definition}

\begin{properties}
    \begin{enumerate}
        \item {
            $0 \leqslant F_{\bar{\xi}} \leqslant 1$
        }
        \item {
            Монотонно возрастает по каждой координате
        }
        \item {
            $\lim_{x_i \to -\infty} F_{\bar{\xi}} (\bar{x}) = 0$

            $\lim_{x_1, \ldots, x_n \to +\infty} F_{\bar{\xi}} (\bar{x}) = 1$
        }
        \item {
            $\lim_{x_i \to +\infty} F_{\bar{\xi}} (\bar{x}) = F_{\xi_1, \ldots, \xi_{i - 1}, \xi_{i + 1}, \ldots}$
        }
    \end{enumerate}
\end{properties}

\begin{definition}
    Совместная плотность $p_{\bar{\xi}} (\bar{t})$ - неотрицательная измеримая функция, такая, что $F_{\bar{\xi}} (\bar{\xi}) = \int_{-\infty}^{x_1} \ldots \int_{-\infty}^{x_n} p_{\bar{\xi}} (\bar{t}) \, dt_n \ldots dt_1$
\end{definition}

\begin{theorem}
    $\xi_1 \ldots \xi_n$ независимы $\Longleftrightarrow F_{\bar{\xi}} (\bar{x}) = F_{\xi_1} (x_1) \cdot \ldots \cdot F_{\xi_n} (x_n)$
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item {
            Докажем $\Rightarrow$. Независимость $\Rightarrow (*) P_{\bar{\xi}} = P_{\xi_1} \times \ldots \times P_{\xi_n} \Rightarrow 
            P_{\bar{\xi}} ((-\infty, x_1] \times \ldots \times (-\infty, x_n]) = P_{\xi_1} (-\infty, x_1] \cdot \ldots \cdot P_{\xi_n} (-\infty, x_n]$
        }
        \item {
            Хотим проверить совпадение на ячейках, чтобы доказать $(*)$ ещё и в другую сторону.

            \begin{center}
                \includegraphics[width=10cm]{assets/02-general-prob-theory/arbitrary-value-independence.png}
            \end{center}

            $P_{\bar{\xi}}((a_1, b_1] \times (a_2, b_2]) = F_{\bar{\xi}} (b_1, b_2)  + F_{\bar{\xi}} (a_1, a_2) - F_{\bar{\xi}} (a_1, b_2) - F_{\bar{\xi}} (a_2, b_1) =$ 

            $= (F_{\xi_1} (b_1) - F_{\xi_1}(a_1)) \cdot (F_{\xi_2}(b_2) - F_{\xi_2}(a_2)) = P_{\xi_1} (a_1, b_1] \cdot P_{\xi_2}(a_2, b_2]$
        }
    \end{enumerate}
\end{proof}

\begin{consequence}
    $\xi_1 \ldots \xi_n$ - абсолютно непрерывные случайные величины. Тогда 
    $\xi_1 \ldots \xi_n$ независимы $\Longleftrightarrow p_{\bar{\xi}} (\bar{t}) = p_{\xi_1} (t_1) \cdot \ldots \cdot p_{\xi_n}(t_n)$

    В частности, в случае независимости $\bar{\xi}$ абсолютно непрерывна.
\end{consequence}

\begin{proof}
    \begin{enumerate}
        \item {
            Докажем $\Rightarrow$.
            
            Независимость $\Rightarrow F_{\bar{\xi}} (\bar{x}) = F_{\xi_1} (x_1) \cdot \ldots \cdot F_{\xi_n} (x_n) = 
            \int_{-\infty}^{x_1} p_{\xi_1} (t_1) \, dt_1 \cdot \ldots \cdot \int_{-\infty}^{x_n} p_{\xi_n} (t_n) \, dt_n = 
            \int_{-\infty}^{x_1} \ldots \int_{-\infty}^{x_n} p_{\xi_1} (t_1) \ldots p_{\xi_n} (t_n) \, dt_n \ldots dt_1$.

            Запихали всё под один интеграл, то что под интегралом и есть совместная плотность.
        }
        \item {
            Докажем $\Leftarrow$.
            
            Просто проинтегрируем равенство.
            
            $\int_{-\infty}^{x_1} \ldots \int_{-\infty}^{x_n} p_{\bar{\xi}} (\bar{t}) \, dt_n \ldots dt_1 = 
            \int_{-\infty}^{x_1} \ldots \int_{-\infty}^{x_n} p_{\xi_1} (t_1) \ldots p_{\xi_n} (t_n) \, dt_n \ldots dt_1 =$
            
            $\underbrace{=}_{\text{по т. Тонелли можно выносить интегралы}} F_{\xi_1} (x_1) \cdot \ldots \cdot F_{\xi_n} (x_n)$
        }
    \end{enumerate}
\end{proof}

\begin{remark}
    Напоминание.

    Свертка последовательностей: $\{a_n\}, \{b_n\}$ это $\{c_n\}$, такая что $c_n = a_0 b_n + a_1 b_{n - 1} + \ldots + a_n b_0$.

    Мотивировка: $\left(\sum_{n=0}^{\infty}a_n z^n\right) \cdot \left(\sum_{n = 0}^{\infty} b_n z^n\right) = \sum_{n=0}^{\infty} c_n z^n$  (при наличии хоть каких-нибудь кругов сходимости у обоих рядов).
\end{remark}

\begin{remark}
    \textbf{Свертки мер}

    $\mu$ и $\nu$ - конечные меры на борелевских подмножествах $\mathbb{R}$.

    $\mu * \nu (A) = \int_{\mathbb{R}} \mu (A - x) \, d\nu (x)$ - это свертка мер, где $(A - x) := \{ a - x \ | \ a \in A \}$.

    \begin{properties}
        \textbf{Свойства свёртки}

        \begin{enumerate}
            \item {
                $\mu * \nu (A) = \int_{\mathbb{R}^2} \mathds{1}_A (x + y) d\mu (x) \, d\nu (y)$

                \textit{Доказательство: } $\mu * \nu (A) = \int_{\mathbb{R}} \mu (A - x) \, d\nu (x) =
                \int_{\mathbb{R}} \int_{\mathbb{R}} \mathds{1}_{A - x} (y) d\mu (y) \, d\nu (x)$
            }
            \item {
                $\mu * \nu = \nu * \mu$
            }
            \item {
                $\mu_1 * \ldots * \mu_n (A) = \int_{\mathbb{R}^n} \mathds{1}_A (x_1 + \ldots + x_n) \, d\mu_1 (x_1) \ldots \, d \mu_n (x_n)$
            }
            \item {
                $(\mu_1 * \mu_2) * \mu_3 = \mu_1 * (\mu_2 * \mu_3)$
            }
            \item {
                $(\mu_1 + \mu_2) * \nu = \mu_1 * \nu + \mu_2 * \nu$
            }
            \item {
                $\delta_x$ - мера с единичной нагрузкой в точке $x$. Тогда $\mu * \delta_0 = \mu$.

                Получили линейное пространство относительно $+$ и $*$

                \textit{Доказательство:} $\mu * \delta_0 (A) = \int_R \mu (A - x) \, d\delta_0 (x) = 
                \mu A$ - значение подыинтегральной функции в точке $x = 0$.
            }
        \end{enumerate}
    \end{properties}
\end{remark}

\begin{theorem}
    Пусть $\mu$ и $\nu$ имеют плотности $p_{\mu}$ и $p_{\nu}$

    Тогда $\mu * \nu$ имеет плотность $p(t) = \int_{\mathbb{R}} p_{\mu} (t - s) p_{\nu} (s) \, ds$
\end{theorem}

\begin{proof}
    Возьмём функцию, определяемую этой формулой и проверим, что подходит.

    $\int_A p(t) \, dt = \int_A \int_{\mathbb{R}} p_{\mu} (t - s) p_{\nu} (s) \, ds \, dt = \int_{\mathbb{R}}
    \int_{\mathbb{R}} \mathds{1}_A (t) p_{\mu} (t - s) p_{\nu} (s) \, ds \, dt = (*)$.

    Положим $u = t - s$. Тогда $(*) = \int_{\mathbb{R}^2} \mathds{1}_{A} (u + s) p_{\mu} (u) p_{\nu} (s) \, ds \, du = 
    \int_{\mathbb{R}^2} \mathds{1}_A (u + s) \, d\nu (s) \, d \mu (u) = \mu * \nu (A)$
\end{proof}

\begin{theorem}
    Если $\xi$ и $\eta$ независимые случайный величины, то $P_{\xi + \eta} = P_{\xi} * P_{\eta}$
\end{theorem}

\begin{proof}
    Нужно взять какое-то борелевское множество и понять как устроено там распределение суммы.

    Пусть $B = \{ (x, y) : x + y \in A \}$

    $P_{\xi + \eta} (A) = P(\xi + \eta \in A) = P((\xi, \eta) \in B) = P_{\xi, \eta} (B) = 
    \int_{\mathbb{R}^2} \mathds{1}_B (x, y) d P_{\xi} (x) \, dP_{\eta} (y) =
    \int_{\mathbb{R}^2} \mathds{1}_A (x + y) d P_{\xi} (x) \, dP_{\eta} (y) = P_{\xi} * P_{\eta} (A)$
\end{proof}

\begin{example}
    \begin{enumerate}
        \item {
            \textbf{Свертка с дисректным распределением}

            $\nu = \sum_{k = 1}^{\infty} p_k \delta_{x_k}$. Тогда $\mu * \nu (A) = \int_{\mathbb{R}} \mu (A - x) \, d\nu (x) = 
            \sum_{k = 1}^{\infty} \mu (A - x_k) p_k$
        }
        \item {
            $\xi_i \sim Poisson(\lambda_i)$. $\xi_1$ и $\xi_2$ независимы.

            $P_{\xi_1 + \xi_2} (\{ n \}) = \sum_{k = 0}^{+\infty} P_{\xi_1} (\{ n  - k \}) \cdot 
            \frac{\lambda_2^k e^{-\lambda_2}}{k!} = \sum_{k = 0}^{n} \frac{\lambda_1^{n - k} e^{-\lambda_1}}{(n - k)!} \cdot 
            \frac{\lambda_2^k e^{-\lambda_2}}{k!} = e^{-\lambda_1} e^{-\lambda_2} \sum_{k = 0}^n \frac{\lambda_1^{n - k} \lambda_2^k}{k! (n - k)!} =
            \frac{(\lambda_1 + \lambda_2)^n e^{-\lambda_1 - \lambda_2}}{n!}$

            $\xi_1 + \xi_2 \sim Poisson(\lambda_1 + \lambda_2)$
        }
    \end{enumerate}
\end{example}



\Subsection{Математическое ожидание и дисперсия}

\begin{definition}
    $\xi : \Omega \rightarrow \mathbb{R}$ - случайная величина ($\xi \geq 0 $, либо суммируемая функция). $\mathbb{E} \xi = \int_{\mathbb{R}} \xi (\omega) \, dP(\omega)$ - математическое ожидание (среднее значение случайной величины).
\end{definition}

\begin{properties}
    \begin{enumerate}
        \item {
            $a, b \in \mathbb{R}: \ \mathbb{E} (a\xi + b \eta) = a\mathbb{E} \xi + b \mathbb{E} \eta$
        }
        \item {
            Если $\xi \geqslant 0$, с вероятностью 1, то $\mathbb{E} \xi \geqslant 0$ (по сути написано, что если функция почти везде неотрицательна, то интеграл неотрицателен).
        }
        \item {
            Если $\xi \geqslant \eta$ с вероятностью 1, то $\mathbb{E}\xi \geqslant \mathbb{E} \eta$
        }
        \item {
            $\mathbb{E} \xi = \int_{\mathbb{R}} x \, dP_{\xi} (x)$
        }
        \item {
            Если $f : \mathbb{R}^n \to \mathbb{R}$ - измерима относительно борелевской $\sigma-$алгебры.

            Тогда $\mathbb{E} f(\xi_1, \xi_2 \ldots \xi_n) = \int_{\mathbb{R}^n} f(x_1, \ldots, x_n) dP_{\xi_1, \ldots, \xi_n} (x_1, \ldots, x_n)$

            \textit{Доказательство:} $f = \mathds{1}_A$. Тогда $\mathbb{E} \mathds{1}_A (\xi_1, \ldots \xi_n) = 
            \int_{\Omega} \mathds{1}_A (\xi_1 (w), \ldots, \xi_n (w)) dP(\omega) = 
            P(\omega \in \Omega : \bar{\xi} \in A) = P_{\bar{\xi}} (A) = \int_{\mathbb{R}^n} \mathds{1}_A (x_1, \ldots, x_n) dP_{\bar{\xi}} (x_1, \ldots, x_n)$.

            Тогда по линейности верно для простых.

            Теперь берём $f_j$ неотрицательный простые, такие, что возрастают и $\rightarrow f$. И предельный
            переход по теореме Леви.
        }
        \item {
            Если $\xi_1$ и $\xi_2$ независимы, то $\mathbb{E} (\xi \cdot \eta) = \mathbb{E} \xi \cdot \mathbb{E} \eta$

            \textit{Доказательство: } $\mathbb{E} (\xi \eta) = \int_{\mathbb{R}^2} xy dP_{\xi, \eta} (x, y) = $
            
            $\underbrace{=}_{\text{независимость сл. вел.}} \int_{\mathbb{R}} \int_{\mathbb{R}} xy dP_{\xi} (x) \, dP_{\eta} (y) =
            \int_{\mathbb{R}} y \int_{\mathbb{R}} x dP_{\xi} (x) \, dP_{\eta} (y) = \mathbb{E} \xi \cdot \mathbb{E} \eta$
        }
        \item {
            Если $\xi \geqslant 0$, то $\mathbb{E} \xi = \int_{0}^{+\infty} P(\xi \geqslant t) \, dt$ - из теории меры.
        }
        \item {
            Если $p, q > 1$ и $\frac{1}{p} + \frac{1}{q} = 1$, то $\mathbb{E}|\xi \eta| \leqslant (\mathbb{E}|\xi|^p)^{\frac{1}{p}} (\mathbb{E} |\eta|^q)^{\frac{1}{q}}$ - 
            неравенство Гёльдера
        }
        \item {
            Неравенство Ляпунова

            $0 < r < s$, тогда $(\mathbb{E} |\xi| ^ r)^{\frac{1}{r}} \leqslant (\mathbb{E}|\xi|^s)^{\frac{1}{s}}$.

            \textit{Доказательство:} $p = \frac{s}{r} > 1, \ \frac{1}{q} = 1 - \frac{1}{p} = \frac{s - r}{s} < 1$.

            Тогда запишем Гельдера для $\xi$ и $\eta = 1$:
            
            $\mathbb{E} |\xi|^r |1| \leq \left(\mathbb{E} (|\xi|^r)^p \right)^{\frac{1}{p}} \cdot \left( \mathbb{E} 1^q \right)^{\frac{1}{q}} = \left( \mathbb{E} |\xi|^s \right)^{\frac{r}{s}}$.
            
            % достаточно доказать для $r = 1$. То есть $\mathbb{E} |\xi| \leqslant (\mathbb{E}|\xi|^s)^{\frac{1}{s}}$.

            % Возьмём $\eta \equiv 1$ и напишем Гёльдера.
        }
    \end{enumerate}
\end{properties}

\begin{remark}
    $\mathbb{E}(\xi \eta) = \mathbb{E}\xi \cdot \mathbb{E} \eta$ без независимости неверно.
    Пример.
    % Тут нужен пример. 
\end{remark}

\begin{theorem}
    \textbf{Неравенство Маркова}

    Если $\xi \geqslant 0, p, t > 0$, то $P(\xi \geqslant t) \leqslant \frac{\mathbb{E}\xi^p}{t^p}$.
\end{theorem}

\begin{proof}
    Неравенство Чебышёва из теории меры.
\end{proof}

\begin{definition}
    \begin{enumerate}
        \item Моменты случайной величины. $\mathbb{E} (\xi^k)$ - $k$-ый момент.
        \item Центральный момент. $\mathbb{E}(\xi - \mathbb{E}\xi)^k$ - $k$-ый центральный момент.
        \item Абсолютный момент. $\mathbb{E}|\xi|^k$ - $k$-ый абсолютный момент.
    \end{enumerate}
\end{definition}

\begin{definition}
    Медиана случайной величины. $m$ - медиана $\xi$, если $P(\xi \geqslant m) \geqslant \frac{1}{2}$ и 
    $P(\xi \leqslant m) \geqslant \frac{1}{2}$.

    \begin{remark}
        Медиана не единственна.

        Возьмём кубик. $\xi = 1, 2, \ldots, 6$ с вероятностью $\frac{1}{6}$. 
        Тогда любое число $m \in [3, 4]$ подходит.

        Чаще всего всё равно берут середину, чтобы была единственность.
    \end{remark}
\end{definition}

\begin{example}
    Есть организация из 1000 человек. 1 начальник и 999 подчиненных.

    Зарплата начальника $1.000.000 \$ $, а подчинённых $1000 \$ $.

    $\mathbb{E} = \frac{999}{1000} \cdot 1000 + \frac{1}{1000} \cdot 1000000 = 1999$

    $m = 1000$ - медиана лучше характеризует ситуацию в этом случае.
\end{example}

\begin{definition}
    Дисперсия. $\mathbb{D} \xi = \mathbb{E}(\xi - \mathbb{E} \xi)^2$ - второй центральный момент.

    Обозначение в англоязычной литературе: $Var \xi$
\end{definition}

\begin{properties}
    \begin{enumerate}
        \item {
            $\mathbb{D} \xi = \mathbb{E} \xi^2 - (\mathbb{E} \xi)^2$

            \textit{Доказательство: } Пусть $a = \mathbb{E} \xi$.

            Тогда $\mathbb{D} \xi = \mathbb{E} (\xi - a)^2 = \mathbb{E} \xi^2 - 2a\mathbb{E}\xi + a^2$
        }
        \item {
            $\mathbb{D} \xi \geqslant 0$ и если $\mathbb{D} \xi = 0$, то $P(\xi = c) = 1$

            \textit{Доказательство: } Если $\mathbb{D} \xi = 0$, то
            $\int_{\Omega} (\xi - a)^2 \, dP = 0$, значит $(\xi - a)^2 = 0$ почти везде.
        }
        \item {
            $\mathbb{D} (\xi + a) = \mathbb{D} \xi$

            \textit{Доказательство: } $\mathbb{E} (\xi + a) = \mathbb{E} \xi + a$. А тогда 
            $(\xi + a) - \mathbb{E} (\xi + a) = \xi - \mathbb{E} \xi$
        }
        \item {
            $\mathbb{D} (c \xi) = c^2 \mathbb{D} \xi$

            \textit{Доказательство: } $\mathbb{D} (c\xi) = \mathbb{E} (c\xi)^2 - (\mathbb{E} (c\xi))^2$
        }
        \item {
            Если $\xi$ и $\eta$ независимы, то $\mathbb{D} (\xi + \eta) = \mathbb{D}\xi + \mathbb{D} \eta$

            \textit{Доказательство: } $\mathbb{D} (\xi + \eta) = \mathbb{E} (\xi + \eta)^2 - (\mathbb{E} (\xi + \eta))^2 = 
            \mathbb{E} \xi^2 + 2\mathbb{E}(\xi \eta) + \mathbb{E} \eta^2 - (\mathbb{E}\xi)^2 - 2\mathbb{E}\xi\mathbb{E}\eta - (\mathbb{E}\eta)^2 = \mathbb{D} \xi + \mathbb{D} \eta$
        }
        \item {
            Аналогично предыдущему, но для $n$ случайных величин.

            \textit{Доказательство: } индукция 
        }
        \item {
            $\mathbb{E} |\xi - \mathbb{E} \xi| \leqslant \sqrt{\mathbb{D} \xi}$

            \textit{Доказательство: } $\mathbb{E} |\xi - \mathbb{E} \xi| \leqslant (\mathbb{E}|\xi - \mathbb{E}\xi|^2)^{\frac{1}{2}} = \sqrt{\mathbb{D} \xi}$ - написали Ляпунова. 
        }
        \item {
            \textbf{Неравенство Чебышёва}

            $P(|\xi - \mathbb{E} \xi| \geqslant t) \leqslant \frac{\mathbb{D} \xi}{t^2}$, где $t > 0$

            \textit{Доказательство: } $P(|\xi - \mathbb{E} \xi| \geqslant t) \leqslant \frac{\mathbb{E} |\xi - \mathbb{E} \xi|^2}{t^2} = \frac{\mathbb{D}\xi}{t^2}$ - неравенство Маркова для $p = 2$. 
        }
    \end{enumerate}
\end{properties}

\begin{definition}
    Стандартное отклонение $\sigma = \sqrt{\mathbb{D} \xi}$
\end{definition}

\begin{example}
    \begin{enumerate}
        \item {
            $\xi \sim U[0, 1]$. 
            
            Тогда $\mathbb{E} \xi = \int_{0}^{1} x \, dx = \frac{x^2}{2} \bigg |_0^1 = \frac{1}{2}$.

            $\mathbb{E} \xi^2 = \int_{0}^{1} x^2 \, dx = \frac{x^3}{3} \bigg |_0^1 = \frac{1}{3}$. А тогда
            $\mathbb{D} \xi = \mathbb{E} \xi^2 - (\mathbb{E} \xi)^2 = \frac{1}{12}$
        }
        \item {
            $\xi \sim U[a, b]$. 
            
            Если $\eta \sim U[0, 1]$ и $\xi = (b - a)\eta + a \sim U[a, b]$.
            Тогда $\mathbb{E} \xi = \mathbb{E} ((b - a) \eta  + a) = \frac{a + b}{2}$

            $\mathbb{D} ((b-a)\eta + a) = \mathbb{D} ((b - a)\eta) = (b-a)^2\mathbb{D}\eta = \frac{(b-a)^2}{12}$
        }
        \item {
            $\xi \sim \mathcal{N} (0, 1)$

            $\mathbb{E} \xi = \frac{1}{\sqrt{2\pi}} \int_{\mathbb{R}} xe^{\frac{-x^2}{2}} \, dx = 0$, так как функция нечётная.

            Значит $\mathbb{D} \xi = \mathbb{E} \xi ^2 = \frac{1}{\sqrt{2\pi}} \int_{\mathbb{R}} x^2 e^{-\frac{x^2}{2}} \, dx = 
            -\frac{e^{\frac{-x^2}{2}}x}{\sqrt{2\pi}} \bigg |_{-\infty}^{+\infty} + \frac{1}{\sqrt{2\pi}} \int_{\mathbb{R}} e^{-\frac{x^2}{2}} \, dx = 1$ 
        }
        \item {
            $\xi \sim \mathcal{N}(a, \sigma^2)$

            Если $\eta \sim \mathcal{N}(0, 1)$, то $\xi = \sigma \eta + a \sim \mathcal{N}(a, \sigma^2)$.
            
            $\mathbb{E} \xi = \mathbb{E} (\sigma \eta + a) = \sigma \mathbb{E} \eta + a = a$

            $\mathbb{D} \xi = \mathbb{D} (\sigma \eta + a) = \sigma^2 \mathbb{D} \eta = \sigma^2$
        }
    \end{enumerate}
\end{example}

\begin{definition}
    Пусть $\mathbb{E} \xi^2 < +\infty$ и $\mathbb{E} \eta^2 < +\infty$.

    Ковариация $cov (\xi, \eta) = \mathbb{E} ((\xi - \mathbb{E}\xi)(\eta - \mathbb{E}\eta))$
\end{definition}

\begin{properties}
    \begin{enumerate}
        \item {
            $cov (\xi, \xi) = \mathbb{D} \xi$
        }
        \item {
            $cov (\xi, \eta) = cov (\eta, \xi)$
        }
        \item {
            $cov (c\xi, \eta) = c \cdot cov (\xi, \eta)$
        }
        \item {
            $cov(\xi_1 + \xi_2, \eta) = cov(\xi_1, \eta) + cov(\xi_2, \eta)$
        }
        \item {
            $cov (\xi, \eta) = \mathbb{E} (\xi \eta) - \mathbb{E}\xi\mathbb{E}\eta$

            \textit{Доказательство: } $\mathbb{E} \xi = a, \mathbb{E} \eta = b$

            $cov(\xi, \eta) = \mathbb{E}((\xi - a)(\eta - b)) = \mathbb{E}(\xi \eta) - a\mathbb{E}\eta - b \mathbb{E} \xi + ab$
        }
        \item {
            Если $\xi$ и $\eta$ независимы, то $cov (\xi, \eta) = 0$
        }
        \item {
            $\mathbb{D} (\xi + \eta) = \mathbb{D} \xi + \mathbb{D} \eta + 2 cov (\xi, \eta)$
        }
        \item {
            $\mathbb{D} (\xi_1 + \xi_2 + \ldots + \xi_n) = \mathbb{D} \xi_1 + \mathbb{D} \xi_2 + \ldots + \mathbb{E} \xi_n + 2\sum_{i < j} cov(\xi_i, \xi_j)$.
        }
    \end{enumerate}
\end{properties}

\begin{example}
    $P(\text{успех}) = p$. Делаем $n$ подбрасываний. $\eta =$ количество переходов от орла к решке.

    Пусть $\xi_i = 1$, если на $i$ позиции орёл, на $i + 1$ позиции решка, иначе $\xi_i = 0$.

    $\eta = \xi_1 + \ldots + \xi_{n - 1}$. Тогда $\mathbb{E} \eta = \sum_{i = 1}^{n - 1} \mathbb{E} \xi_i = (n - 1)pq$.

    $\mathbb{D} \eta = \sum_{i = 1}^{n - 1} \mathbb{D}\xi_i + 2\sum_{i < j} cov(\xi_i, \xi_j)$.

    Если $i + 1 < j$, то $\xi_i$ и $\xi_j$ независимы, поэтому в сумме почти везде нули.

    Значит $\mathbb{D} \eta = \sum_{i = 1}^{n - 1} \mathbb{D}\xi_i + 2\sum_{i = 1}^{n - 1} cov(\xi_i, \xi_{i + 1})$.

    $\mathbb{D} \xi_i = \mathbb{E} \xi_i^2 - (\mathbb{E} \xi_i)^2 = pq - p^2q^2$.

    $cov(\xi, \xi_{i + 1}) = \mathbb{E} (\xi_i \xi_{i + 1}) - \mathbb{E} \xi_i \mathbb{E} \xi_{i + 1} = -p^2q^2$
\end{example}

\begin{remark}
    \begin{enumerate}
        \item {
            $\{ \xi : \mathbb{E} \xi^2 < +\infty \}$

            $\left <\xi, \eta \right > = \mathbb{E} (\xi \eta)$ - скалярное произведение.

            $\mathbb{E} \xi$ - ортогональная проекция на константы.
        }
        \item {
            $\left < \xi, \eta \right > = cov (\xi, \eta)$ - тоже скалярное произведение.

            Норма - это стандартное отклонение.
        }
    \end{enumerate}
\end{remark}

\begin{theorem}
    \textbf{Выбор двудольного подграфа}

    Есть граф $G$ с $n$ вершинами и $m$ рёбрами. Хотим стереть некоторое количество рёбер(как можно меньше) так, чтобы
    остался двудольный подграф.

    Тогда $G$ содержит двудольный подграф с $\geqslant \frac{m}{2}$ рёбрами.
\end{theorem}

\begin{proof}
    $A$ - те вершины, на которых выпал орёл, $B$ - на которых выпала решка.

    Будем интересоваться матожидание количества рёбер в такой ситуации.

    $
    \xi_{xy} = 
    \begin{cases}
        1, & \text{если x, y из разных долей} \\
        0, & \text{иначе}
    \end{cases}
    $

    $\mathbb{E} \xi = \sum_{xy \in E} \mathbb{E} \xi_{xy} = \frac{m}{2}$, а значит есть реализация с $\frac{m}{2}$.
\end{proof}
    